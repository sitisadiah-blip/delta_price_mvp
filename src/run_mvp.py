import os
import sys
import argparse
import json
import warnings
import platform
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
# æ³¨æ„ï¼šLightGBM å’Œ HistGBDT ä¼šåœ¨éœ€è¦æ—¶åŠ¨æ€å¯¼å…¥

# ================= é…ç½®ä¸åˆå§‹åŒ– =================
# å¿½ç•¥ä¸€äº›æ— å…³ç´§è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=RuntimeWarning)

DIRS = ["data", "outputs/figures", "outputs/metrics"]
for d in DIRS:
    os.makedirs(d, exist_ok=True)

# ä¿®å¤ä¸­æ–‡ä¹±ç çš„å…³é”®è®¾ç½®
def setup_plotting_style():
    """æ ¹æ®æ“ä½œç³»ç»Ÿè‡ªåŠ¨è®¾ç½® Matplotlib å­—ä½“"""
    system_name = platform.system()
    if system_name == "Darwin":  # macOS
        # å°è¯• macOS å¸¸è§ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC', 'Heiti TC']
    elif system_name == "Windows":
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
    else:
        # Linux/Docker ç¯å¢ƒ
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'DejaVu Sans']
    
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºæ–¹å—çš„é—®é¢˜

# ================= æ ¸å¿ƒé€»è¾‘å‡½æ•° =================

def load_data_auto(data_dir="data"):
    """æ™ºèƒ½åŠ è½½æ•°æ®ï¼šè‡ªåŠ¨å¯»æ‰¾ xlsx æˆ– csvï¼Œå¹¶å¤„ç†ä¾èµ–ç¼ºå¤±"""
    # ä¼˜å…ˆæŸ¥æ‰¾ xlsx (å› ä¸ºé€šå¸¸åŒ…å«åŸå§‹æ ¼å¼)
    xlsx_files = glob.glob(os.path.join(data_dir, "*.xlsx"))
    csv_files = glob.glob(os.path.join(data_dir, "*.csv"))
    
    file_path = None
    
    # å°è¯•åŠ è½½ xlsx
    if xlsx_files:
        try:
            import openpyxl
            file_path = xlsx_files[0]
            print(f"ğŸ“– å‘ç° Excel æ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–: {os.path.basename(file_path)}")
            return pd.read_excel(file_path)
        except ImportError:
            print("âš ï¸ å‘ç° .xlsx æ–‡ä»¶ä½†ç¼ºå°‘ 'openpyxl' åº“ã€‚å»ºè®®è¿è¡Œ pip install openpyxl")
            print("ğŸ”„ å°è¯•å¯»æ‰¾ CSV æ–‡ä»¶ä½œä¸ºæ›¿ä»£...")
    
    # å°è¯•åŠ è½½ csv
    if csv_files:
        # ä¼˜å…ˆç”¨çœ‹èµ·æ¥åƒä¸»æ•°æ®çš„ï¼ˆæ’é™¤ data_description ç­‰ï¼‰
        candidates = [f for f in csv_files if "description" not in f and "result" not in f]
        if candidates:
            file_path = candidates[0]
        else:
            file_path = csv_files[0]
        print(f"ğŸ“– æ­£åœ¨è¯»å– CSV æ–‡ä»¶: {os.path.basename(file_path)}")
        return pd.read_csv(file_path)
    
    raise FileNotFoundError("âŒ åœ¨ data/ ç›®å½•ä¸‹æœªæ‰¾åˆ° train.xlsx æˆ– .csv æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ ã€‚")

def build_features_v2(df, target_col, date_col, drop_cols):
    """ç‰¹å¾å·¥ç¨‹ V2ï¼šå¢å¼ºæ—¶é—´ç‰¹å¾"""
    df = df.copy()
    
    # 1. æå–ç›®æ ‡å˜é‡
    if target_col not in df.columns:
        raise ValueError(f"æ•°æ®ä¸­æ‰¾ä¸åˆ°ç›®æ ‡åˆ— '{target_col}'")
    y = df[target_col].astype(float)
    X = df.drop(columns=[target_col])

    # 2. å¤„ç†ä¸éœ€è¦çš„åˆ— (å¦‚ ID)
    for c in drop_cols:
        if c in X.columns:
            X = X.drop(columns=[c])

    # 3. å¢å¼ºå‹æ—¶é—´å¤„ç†
    if date_col in X.columns:
        print(f"âš™ï¸ æ­£åœ¨å¤„ç†æ—¶é—´ç‰¹å¾: {date_col}")
        dt = pd.to_datetime(X[date_col])
        
        # A. é•¿æœŸè¶‹åŠ¿ï¼šè·ç¦»æœ€æ—©äº¤æ˜“æ—¥çš„å¤©æ•° (æ›¿ä»£åŸæ¥çš„ ordinal)
        X['days_since_start'] = (dt - dt.min()).dt.days
        
        # B. å‘¨æœŸæ€§ç‰¹å¾ï¼šæ˜¯å¦å‘¨æœ« (æµé‡é€šå¸¸æ›´å¤§)
        X['is_weekend'] = dt.dt.dayofweek.isin([5, 6]).astype(int)
        
        # ç§»é™¤åŸå§‹æ—¶é—´å­—ç¬¦ä¸²
        X = X.drop(columns=[date_col])
    
    # 4. ç®€å•çš„ç¼ºå¤±å€¼å¡«å…… (æ•°å€¼å‹å¡«ä¸­ä½æ•°ï¼Œç±»åˆ«å‹å¡«0)
    # å®é™…é¡¹ç›®ä¸­åº”æ›´ç²¾ç»†ï¼Œè¿™é‡Œä¸ºäº† MVP å¿«é€Ÿè·‘é€š
    num_cols = X.select_dtypes(include=[np.number]).columns
    X[num_cols] = X[num_cols].fillna(X[num_cols].median())
    
    return X, y

def evaluate(name, y_true, y_pred):
    """ç»Ÿä¸€è¯„ä¼°å‡½æ•°"""
    return {
        "model": name,
        "MAE": float(mean_absolute_error(y_true, y_pred)),
        "RMSE": float(np.sqrt(mean_squared_error(y_true, y_pred))),
        "R2": float(r2_score(y_true, y_pred)),
        "n": int(len(y_true))
    }

def plot_pred_scatter(y_true, y_pred, title, path):
    """ç»˜åˆ¶é¢„æµ‹å€¼ vs çœŸå®å€¼æ•£ç‚¹å›¾"""
    plt.figure(figsize=(6, 6))
    plt.scatter(y_true, y_pred, alpha=0.3, s=10)
    
    # ç”»å¯¹è§’çº¿
    limit_min = min(y_true.min(), y_pred.min())
    limit_max = max(y_true.max(), y_pred.max())
    plt.plot([limit_min, limit_max], [limit_min, limit_max], 'r--', lw=2, label="å®Œç¾é¢„æµ‹çº¿")
    
    plt.title(title)
    plt.xlabel("çœŸå®å€¼ (Transformed)")
    plt.ylabel("é¢„æµ‹å€¼ (Transformed)")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(path, dpi=150)
    plt.close()

# ================= ä¸»ç¨‹åº =================

def main():
    setup_plotting_style()
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--winsorize", action="store_true", help="æ˜¯å¦å¯¹ç›®æ ‡å˜é‡åš1%-99%ç¼©å°¾å¤„ç†")
    parser.add_argument("--log_target", action="store_true", help="æ˜¯å¦å¯¹ç›®æ ‡å˜é‡å– log1p")
    parser.add_argument("--cv", action="store_true", help="æ˜¯å¦è·‘äº¤å‰éªŒè¯ (é€Ÿåº¦è¾ƒæ…¢)")
    args = parser.parse_args()

    # 1. åŠ è½½æ•°æ®
    try:
        raw_df = load_data_auto()
    except Exception as e:
        print(f"{e}")
        return

    # 2. ç‰¹å¾å·¥ç¨‹
    # æ ¹æ®ä½ çš„æ•°æ®åˆ—åé…ç½®
    TARGET_COL = "ä»·æ ¼"
    DATE_COL = "æˆäº¤æ—¶é—´"
    DROP_COLS = ["å•†å“å·"] # IDç±»æ— ç”¨ç‰¹å¾
    
    X, y = build_features_v2(raw_df, TARGET_COL, DATE_COL, DROP_COLS)
    
    print(f"ğŸ“Š æ•°æ®å‡†å¤‡å®Œæ¯•: æ ·æœ¬æ•° {X.shape[0]}, ç‰¹å¾æ•° {X.shape[1]}")

    # 3. åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 4. ç›®æ ‡å˜é‡å˜æ¢ (ç¼©å°¾ + Log)
    y_train_work = y_train.copy()
    y_test_work = y_test.copy()
    transform_note = []

    if args.winsorize:
        lower = y_train.quantile(0.01)
        upper = y_train.quantile(0.99)
        y_train_work = y_train_work.clip(lower, upper)
        y_test_work = y_test_work.clip(lower, upper)
        transform_note.append("winsorize(1%,99%)")
    
    if args.log_target:
        y_train_work = np.log1p(y_train_work)
        y_test_work = np.log1p(y_test_work)
        transform_note.append("log1p")
    
    transform_desc = "+".join(transform_note) if transform_note else "none"
    print(f"ğŸ”„ ç›®æ ‡å˜é‡å˜æ¢: {transform_desc}")

    results = []

    # === æ¨¡å‹ 1: Ridge (çº¿æ€§åŸºçº¿) ===
    print("\nğŸš€ æ­£åœ¨è®­ç»ƒ Ridge å›å½’...")
    ridge = Pipeline([
        ('scaler', StandardScaler()),
        ('regressor', Ridge())
    ])
    ridge.fit(X_train, y_train_work)
    pred_ridge = ridge.predict(X_test)
    
    res_ridge = evaluate("Ridge", y_test_work, pred_ridge)
    res_ridge['target_transform'] = transform_desc
    results.append(res_ridge)
    
    plot_pred_scatter(y_test_work, pred_ridge, 
                      f"Ridge é¢„æµ‹å¯¹æ¯” (R2={res_ridge['R2']:.3f})", 
                      "outputs/figures/scatter_ridge.png")

    # === æ¨¡å‹ 2: GBDT (ä¼˜å…ˆ LightGBMï¼Œå¤±è´¥é™çº§ HistGBDT) ===
    print("\nğŸš€ æ­£åœ¨è®­ç»ƒ GBDT æ ‘æ¨¡å‹...")
    gbdt_model = None
    model_name = "Unknown"

    try:
        import lightgbm as lgb
        print("âœ… æ£€æµ‹åˆ° LightGBMï¼Œæ­£åœ¨å°è¯•è®­ç»ƒ...")
        # æ˜¾å¼è®¾ç½® n_jobs=1 å¯ä»¥ç¼“è§£æŸäº› macOS OpenMP å†²çªï¼Œæˆ–è€…è®©å®ƒè‡ªåŠ¨
        gbdt_model = lgb.LGBMRegressor(random_state=42, verbose=-1)
        gbdt_model.fit(X_train, y_train_work)
        model_name = "LightGBM"
    
    except Exception as e:
        print(f"âš ï¸ LightGBM å¯åŠ¨å¤±è´¥ (é€šå¸¸æ˜¯å› ä¸º macOS ç¼ºå°‘ libomp)ã€‚")
        print(f"   é”™è¯¯è¯¦æƒ…: {str(e)[:100]}...")
        print("ğŸ”„ æ­£åœ¨é™çº§ä½¿ç”¨ Scikit-learn çš„ HistGradientBoostingRegressor (æ•ˆæœç›¸è¿‘)...")
        
        from sklearn.ensemble import HistGradientBoostingRegressor
        gbdt_model = HistGradientBoostingRegressor(random_state=42)
        gbdt_model.fit(X_train, y_train_work)
        model_name = "HistGBDT(sklearn)"

    # ç»Ÿä¸€é¢„æµ‹è¯„ä¼°
    pred_gbdt = gbdt_model.predict(X_test)
    res_gbdt = evaluate(model_name, y_test_work, pred_gbdt)
    res_gbdt['target_transform'] = transform_desc
    results.append(res_gbdt)

    plot_pred_scatter(y_test_work, pred_gbdt, 
                      f"{model_name} é¢„æµ‹å¯¹æ¯” (R2={res_gbdt['R2']:.3f})", 
                      "outputs/figures/scatter_gbdt.png")
    
    # === è¾“å‡ºæ€»ç»“ ===
    res_df = pd.DataFrame(results)
    print("\nğŸ† æœ€ç»ˆæˆç»©å•:")
    print(res_df[['model', 'MAE', 'RMSE', 'R2']])
    
    res_df.to_csv("outputs/metrics/final_results.csv", index=False)
    print(f"\nâœ¨ è¿è¡Œç»“æŸï¼ç»“æœå·²ä¿å­˜è‡³ outputs/metrics/final_results.csv")
    print(f"ğŸ–¼ï¸  å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³ outputs/figures/ ç›®å½•")

if __name__ == "__main__":
    main()
